{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from scipy.stats import entropy, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_mix = {\n",
    "    'algorithm': CategoricalDtype(['BisectingKMeans', 'GBT', 'GMM', 'KMeans', 'Linear', 'Logistic', 'MLP', 'RFR', 'Tree']),\n",
    "    'dataset': CategoricalDtype(['drift', 'drivface', 'drugs', 'geomagnetic', 'higgs']),\n",
    "    'family': CategoricalDtype(['classification', 'clustering', 'regression']),\n",
    "    'platformId': 'int',\n",
    "    'runId': 'int',\n",
    "    'splitter': CategoricalDtype(['none', 'random-80-20']),\n",
    "}\n",
    "\n",
    "dtype_platform = {\n",
    "    'jobId': 'int',\n",
    "    'jobGroup': 'category',\n",
    "    'stageId': 'int',\n",
    "    'taskId': 'int',\n",
    "    'launchTime': 'int',\n",
    "    'finishTime': 'int',\n",
    "    'duration': 'int',\n",
    "    'schedulerDelay': 'int',\n",
    "    'executorId': 'int',\n",
    "    'host': 'category',\n",
    "    'taskLocality': 'category',\n",
    "    'speculative': 'bool',\n",
    "    'gettingResultTime': 'int',\n",
    "    'successful': 'bool',\n",
    "    'executorRunTime': 'int',\n",
    "    'executorCpuTime': 'int',\n",
    "    'executorDeserializeTime': 'int',\n",
    "    'executorDeserializeCpuTime': 'int',\n",
    "    'resultSerializationTime': 'int',\n",
    "    'jvmGCTime': 'int',\n",
    "    'resultSize': 'int',\n",
    "    'numUpdatedBlockStatuses': 'int',\n",
    "    'diskBytesSpilled': 'int',\n",
    "    'memoryBytesSpilled': 'int',\n",
    "    'peakExecutionMemory': 'int',\n",
    "    'recordsRead': 'int',\n",
    "    'bytesRead': 'int',\n",
    "    'recordsWritten': 'int',\n",
    "    'bytesWritten': 'int',\n",
    "    'shuffleFetchWaitTime': 'int',\n",
    "    'shuffleTotalBytesRead': 'int',\n",
    "    'shuffleTotalBlocksFetched': 'int',\n",
    "    'shuffleLocalBlocksFetched': 'int',\n",
    "    'shuffleRemoteBlocksFetched': 'int',\n",
    "    'shuffleWriteTime': 'int',\n",
    "    'shuffleBytesWritten': 'int',\n",
    "    'shuffleRecordsWritten': 'int',\n",
    "    'phase': 'category',\n",
    "    **dtype_mix\n",
    "}\n",
    "\n",
    "dtype_applicative = {\n",
    "    'transformTime': 'int',\n",
    "    'features': 'int',\n",
    "    'fitTime': 'int',\n",
    "    'testCount': 'int',\n",
    "    'trainCount': 'int',\n",
    "    'r2': 'float',\n",
    "    'mse': 'float',\n",
    "    'mae': 'float',\n",
    "    'rmse': 'float', \n",
    "    'silhouette': 'float',\n",
    "    'accuracy': 'float',\n",
    "    'weightedRecall': 'float',\n",
    "    'f1': 'float',\n",
    "    'weightedPrecision': 'float',\n",
    "    **dtype_mix\n",
    "}\n",
    "\n",
    "dtype_configuration = {\n",
    "    'platformId': 'int',\n",
    "    'spark.shuffle.compress': 'bool',\n",
    "    'spark.master': 'category',\n",
    "    'spark.io.compression.codec': 'category',\n",
    "    'spark.shuffle.file.buffer': 'int',\n",
    "    'spark.storage.memoryFraction': 'float',\n",
    "    'spark.shuffle.io.preferDirectBufs': 'bool',\n",
    "    'spark.rdd.compress': 'bool',\n",
    "    'spark.dynamicAllocation.enabled': 'bool',\n",
    "    'spark.executor.memory': 'int',\n",
    "    'spark.driver.cores': 'int',\n",
    "    'spark.executor.cores': 'int',\n",
    "    'spark.driver.memory': 'int',\n",
    "    'spark.reducer.maxSizeInFlight': 'int',\n",
    "    'spark.serializer': 'category',\n",
    "    'spark.shuffle.spill.compress': 'bool',\n",
    "    'spark.executor.instances': 'int',\n",
    "    'spark.locality.wait': 'int'\n",
    "}\n",
    "\n",
    "mapping = {\n",
    "    '32k': 32 * 1000,\n",
    "    '16k': 16 * 1000,\n",
    "    '64k': 64 * 1000,\n",
    "    '5g': 5 * 1000 ** 3,\n",
    "    '2g': 2 * 1000 ** 3,\n",
    "    '10g': 10 * 1000 ** 3,\n",
    "    '3s': 3 * 1000,\n",
    "    '10ms': 10,\n",
    "    '1ms': 1,\n",
    "    '48m': 48 * 1000 ** 2,\n",
    "    '24m': 24 * 1000 ** 2,\n",
    "    '72m': 72 * 1000 ** 2,\n",
    "    '': -1\n",
    "}\n",
    "\n",
    "def to_numeric(number):\n",
    "    return mapping[number] if number in mapping else int(number)\n",
    "\n",
    "converters_configuration = {\n",
    "    'spark.shuffle.file.buffer': to_numeric,\n",
    "    'spark.locality.wait': to_numeric,\n",
    "    'spark.driver.memory': to_numeric,\n",
    "    'spark.executor.memory': to_numeric,\n",
    "    'spark.reducer.maxSizeInFlight': to_numeric,\n",
    "    'spark.executor.instances': to_numeric\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = pd.read_csv('../results/platform.csv', header=0, engine='c', na_filter=False, dtype=dtype_platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicative = pd.read_csv('../results/applicative.csv', header=0, engine='c', dtype=dtype_applicative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Both a converter and dtype were specified for column spark.shuffle.file.buffer - only the converter will be used\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Both a converter and dtype were specified for column spark.executor.memory - only the converter will be used\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Both a converter and dtype were specified for column spark.driver.memory - only the converter will be used\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Both a converter and dtype were specified for column spark.reducer.maxSizeInFlight - only the converter will be used\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Both a converter and dtype were specified for column spark.executor.instances - only the converter will be used\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Both a converter and dtype were specified for column spark.locality.wait - only the converter will be used\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "configuration = pd.read_csv('../results/configuration.csv', header=0, engine='c', na_filter=False, converters=converters_configuration, dtype=dtype_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicative_configuration = pd.merge(applicative, configuration, left_on='platformId', right_on='platformId', suffixes=('', '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(platform, applicative_configuration, left_on=['algorithm', 'dataset', 'platformId', 'runId'], right_on=['algorithm', 'dataset', 'platformId', 'runId'], suffixes=('', '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlations(data, y):\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        algorithm + '-' + dataset:\n",
    "            correlation(data[(data['algorithm'] == algorithm) & (data['dataset'] == dataset)], y=y)\n",
    "        #for phase in ['transform']\n",
    "        for algorithm in data['algorithm'].cat.categories.sort_values()\n",
    "        for dataset in data['dataset'].cat.categories.sort_values()\n",
    "    })\n",
    "\n",
    "def remove_nan(data):\n",
    "    \n",
    "    if np.isnan(data):\n",
    "        return 0\n",
    "\n",
    "    return data\n",
    "\n",
    "def correlation(data, y):\n",
    "\n",
    "    return pd.Series({\n",
    "        feature: remove_nan(pearsonr(data[feature], data[y])[0])\n",
    "        for feature in data\n",
    "        if feature not in ['dataset', 'algorithm', 'duration', 'phase', 'fitTime', 'transformTime']\n",
    "    })\n",
    "\n",
    "def count(corr, k):\n",
    "    \n",
    "    total = {}\n",
    "\n",
    "    for couple in corr:\n",
    "\n",
    "        top = corr[couple].abs().nlargest(k).index\n",
    "\n",
    "        for metric in top:\n",
    "\n",
    "            if metric not in total:\n",
    "                total[metric] = 1\n",
    "            else:\n",
    "                total[metric] += 1\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = applicative_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spark.io.compression.codec'] = data['spark.io.compression.codec'].cat.codes\n",
    "data['spark.serializer'] = data['spark.serializer'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'spark.shuffle.compress': [0, 12],\n",
    "    'spark.io.compression.codec': [0, 7],\n",
    "    'spark.shuffle.file.buffer': [0, 13,14],\n",
    "    'spark.storage.memoryFraction': [0, 17,18],\n",
    "    'spark.shuffle.io.preferDirectBufs': [0, 15],\n",
    "    'spark.rdd.compress': [0, 8],\n",
    "    'spark.executor.memory': [0, 5,6],\n",
    "    'spark.executor.cores': [0, 1,2],\n",
    "    'spark.reducer.maxSizeInFlight': [0, 9,10],\n",
    "    'spark.serializer': [0, 11],\n",
    "    'spark.shuffle.spill.compress': [0, 16],\n",
    "    'spark.executor.instances': [0, 3,4],\n",
    "    'spark.locality.wait': [0, 19,20],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-526d7ec1b9ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'algorithm'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MLP'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'higgs'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'platformId'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'platformId'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'platformId'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2916\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2920\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   3353\u001b[0m         \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3354\u001b[0m         \"\"\"\n\u001b[0;32m-> 3355\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3357\u001b[0m         new_data = self._data.take(indices,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5136\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5125\u001b[0m         \"\"\"\n\u001b[1;32m   5126\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5127\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5135\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   1897\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 1899\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   1900\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   3144\u001b[0m         \u001b[0;31m# combination of those slices is a slice, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3146\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3148\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[1;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "select = data[(data['algorithm'] == 'MLP') & (data['dataset'] == 'higgs') & ((data['platformId'] == 0) | (data['platformId'] == 13) | (data['platformId'] == 14))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-191c8efd39db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'platformId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'algorithm'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2916\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2920\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   3353\u001b[0m         \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3354\u001b[0m         \"\"\"\n\u001b[0;32m-> 3355\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3357\u001b[0m         new_data = self._data.take(indices,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5136\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5125\u001b[0m         \"\"\"\n\u001b[1;32m   5126\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5127\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5135\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   1897\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 1899\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   1900\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   3147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3148\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3149\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3150\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "for algorithm in tqdm(data['algorithm'].cat.categories.sort_values()):\n",
    "\n",
    "    for dataset in tqdm(data['dataset'].cat.categories.sort_values()):\n",
    "\n",
    "        for config, ids in tqdm(mapping.items()):\n",
    "\n",
    "            selection = data[(data['dataset'] == dataset) & (data['algorithm'] == algorithm) & np.isin(data['platformId'], ids)]\n",
    "\n",
    "            corr = pearsonr(selection['duration'], selection[config])[0]\n",
    "\n",
    "            res.append(pd.Series({\"dataset\": dataset, 'algorithm': algorithm, 'config': config, 'corr': corr, 'family': selection['family'].iloc[0] if len(selection) else None}))\n",
    "\n",
    "res = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['corr'] = res['corr'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = res.set_index(['config', 'family']).groupby(['dataset', 'algorithm'])['corr'].nlargest(4, keep='all').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark.executor.cores                 32\n",
       "spark.serializer                     26\n",
       "spark.rdd.compress                   17\n",
       "spark.executor.memory                15\n",
       "spark.io.compression.codec           12\n",
       "spark.shuffle.spill.compress         11\n",
       "spark.reducer.maxSizeInFlight        10\n",
       "spark.shuffle.file.buffer             9\n",
       "spark.shuffle.io.preferDirectBufs     9\n",
       "spark.storage.memoryFraction          8\n",
       "spark.executor.instances              8\n",
       "spark.shuffle.compress                8\n",
       "spark.locality.wait                   7\n",
       "Name: config, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['config'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family          config                           \n",
       "classification  spark.executor.cores                 12\n",
       "                spark.serializer                     10\n",
       "                spark.executor.memory                 6\n",
       "                spark.rdd.compress                    5\n",
       "                spark.reducer.maxSizeInFlight         4\n",
       "                spark.storage.memoryFraction          4\n",
       "                spark.executor.instances              3\n",
       "                spark.io.compression.codec            3\n",
       "                spark.locality.wait                   3\n",
       "                spark.shuffle.file.buffer             3\n",
       "                spark.shuffle.spill.compress          3\n",
       "                spark.shuffle.compress                2\n",
       "                spark.shuffle.io.preferDirectBufs     2\n",
       "clustering      spark.executor.cores                  8\n",
       "                spark.executor.memory                 6\n",
       "                spark.serializer                      6\n",
       "                spark.executor.instances              4\n",
       "                spark.io.compression.codec            4\n",
       "                spark.rdd.compress                    4\n",
       "                spark.shuffle.io.preferDirectBufs     4\n",
       "                spark.shuffle.spill.compress          4\n",
       "                spark.locality.wait                   3\n",
       "                spark.reducer.maxSizeInFlight         3\n",
       "                spark.shuffle.compress                3\n",
       "                spark.storage.memoryFraction          2\n",
       "                spark.shuffle.file.buffer             1\n",
       "regression      spark.executor.cores                 12\n",
       "                spark.serializer                     10\n",
       "                spark.rdd.compress                    8\n",
       "                spark.io.compression.codec            5\n",
       "                spark.shuffle.file.buffer             5\n",
       "                spark.shuffle.spill.compress          4\n",
       "                spark.executor.memory                 3\n",
       "                spark.reducer.maxSizeInFlight         3\n",
       "                spark.shuffle.compress                3\n",
       "                spark.shuffle.io.preferDirectBufs     3\n",
       "                spark.storage.memoryFraction          2\n",
       "                spark.executor.instances              1\n",
       "                spark.locality.wait                   1\n",
       "Name: config, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.groupby('family')['config'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>config</th>\n",
       "      <th>family</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drift</td>\n",
       "      <td>BisectingKMeans</td>\n",
       "      <td>spark.serializer</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.761351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drift</td>\n",
       "      <td>BisectingKMeans</td>\n",
       "      <td>spark.reducer.maxSizeInFlight</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.451746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drift</td>\n",
       "      <td>BisectingKMeans</td>\n",
       "      <td>spark.executor.instances</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.376804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drift</td>\n",
       "      <td>BisectingKMeans</td>\n",
       "      <td>spark.executor.cores</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.364779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drift</td>\n",
       "      <td>GBT</td>\n",
       "      <td>spark.rdd.compress</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.485571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>drift</td>\n",
       "      <td>GBT</td>\n",
       "      <td>spark.locality.wait</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.448519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>drift</td>\n",
       "      <td>GBT</td>\n",
       "      <td>spark.serializer</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.405312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>drift</td>\n",
       "      <td>GBT</td>\n",
       "      <td>spark.shuffle.spill.compress</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.379202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>drift</td>\n",
       "      <td>GMM</td>\n",
       "      <td>spark.io.compression.codec</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.547946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>drift</td>\n",
       "      <td>GMM</td>\n",
       "      <td>spark.serializer</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.383796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>drift</td>\n",
       "      <td>GMM</td>\n",
       "      <td>spark.locality.wait</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.339130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>drift</td>\n",
       "      <td>GMM</td>\n",
       "      <td>spark.executor.memory</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.291832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>drift</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>spark.executor.cores</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.727143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>drift</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>spark.shuffle.io.preferDirectBufs</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.481616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>drift</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>spark.serializer</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.378786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>drift</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>spark.executor.memory</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.364115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>drift</td>\n",
       "      <td>Linear</td>\n",
       "      <td>spark.shuffle.file.buffer</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.575189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>drift</td>\n",
       "      <td>Linear</td>\n",
       "      <td>spark.reducer.maxSizeInFlight</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.531954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>drift</td>\n",
       "      <td>Linear</td>\n",
       "      <td>spark.io.compression.codec</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.369945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>drift</td>\n",
       "      <td>Linear</td>\n",
       "      <td>spark.executor.cores</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.309268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>drift</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>spark.reducer.maxSizeInFlight</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.542878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>drift</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>spark.serializer</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.487533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>drift</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>spark.shuffle.compress</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.289387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>drift</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>spark.rdd.compress</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.270352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>drift</td>\n",
       "      <td>MLP</td>\n",
       "      <td>spark.serializer</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.549565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>drift</td>\n",
       "      <td>MLP</td>\n",
       "      <td>spark.executor.cores</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.482878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>drift</td>\n",
       "      <td>MLP</td>\n",
       "      <td>spark.reducer.maxSizeInFlight</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.300109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>drift</td>\n",
       "      <td>MLP</td>\n",
       "      <td>spark.locality.wait</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.277702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>drift</td>\n",
       "      <td>RFR</td>\n",
       "      <td>spark.shuffle.file.buffer</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.439532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>drift</td>\n",
       "      <td>RFR</td>\n",
       "      <td>spark.executor.cores</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.367706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>higgs</td>\n",
       "      <td>GBT</td>\n",
       "      <td>spark.rdd.compress</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.426161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>higgs</td>\n",
       "      <td>GBT</td>\n",
       "      <td>spark.reducer.maxSizeInFlight</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.301010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>higgs</td>\n",
       "      <td>GMM</td>\n",
       "      <td>spark.executor.cores</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.872452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>higgs</td>\n",
       "      <td>GMM</td>\n",
       "      <td>spark.locality.wait</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.613022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>higgs</td>\n",
       "      <td>GMM</td>\n",
       "      <td>spark.shuffle.compress</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.513397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>higgs</td>\n",
       "      <td>GMM</td>\n",
       "      <td>spark.rdd.compress</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.382530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>higgs</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>spark.executor.cores</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.796475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>higgs</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>spark.rdd.compress</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.606863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>higgs</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>spark.io.compression.codec</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.524419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>higgs</td>\n",
       "      <td>KMeans</td>\n",
       "      <td>spark.shuffle.spill.compress</td>\n",
       "      <td>clustering</td>\n",
       "      <td>0.495950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Linear</td>\n",
       "      <td>spark.executor.cores</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.830322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Linear</td>\n",
       "      <td>spark.serializer</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.508103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Linear</td>\n",
       "      <td>spark.rdd.compress</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.350343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Linear</td>\n",
       "      <td>spark.io.compression.codec</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.342071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>spark.executor.cores</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.740345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>spark.rdd.compress</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.695201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>spark.locality.wait</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.525535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>spark.serializer</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.313255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>higgs</td>\n",
       "      <td>MLP</td>\n",
       "      <td>spark.executor.cores</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.527106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>higgs</td>\n",
       "      <td>MLP</td>\n",
       "      <td>spark.storage.memoryFraction</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.428811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>higgs</td>\n",
       "      <td>MLP</td>\n",
       "      <td>spark.executor.memory</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.384922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>higgs</td>\n",
       "      <td>MLP</td>\n",
       "      <td>spark.serializer</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.346812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>higgs</td>\n",
       "      <td>RFR</td>\n",
       "      <td>spark.serializer</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.537009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>higgs</td>\n",
       "      <td>RFR</td>\n",
       "      <td>spark.rdd.compress</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.424055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>higgs</td>\n",
       "      <td>RFR</td>\n",
       "      <td>spark.io.compression.codec</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.410668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>higgs</td>\n",
       "      <td>RFR</td>\n",
       "      <td>spark.storage.memoryFraction</td>\n",
       "      <td>regression</td>\n",
       "      <td>0.302768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Tree</td>\n",
       "      <td>spark.serializer</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.848753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Tree</td>\n",
       "      <td>spark.storage.memoryFraction</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.655175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Tree</td>\n",
       "      <td>spark.executor.cores</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.492446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>higgs</td>\n",
       "      <td>Tree</td>\n",
       "      <td>spark.shuffle.spill.compress</td>\n",
       "      <td>classification</td>\n",
       "      <td>0.372471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset        algorithm                             config  \\\n",
       "0     drift  BisectingKMeans                   spark.serializer   \n",
       "1     drift  BisectingKMeans      spark.reducer.maxSizeInFlight   \n",
       "2     drift  BisectingKMeans           spark.executor.instances   \n",
       "3     drift  BisectingKMeans               spark.executor.cores   \n",
       "4     drift              GBT                 spark.rdd.compress   \n",
       "5     drift              GBT                spark.locality.wait   \n",
       "6     drift              GBT                   spark.serializer   \n",
       "7     drift              GBT       spark.shuffle.spill.compress   \n",
       "8     drift              GMM         spark.io.compression.codec   \n",
       "9     drift              GMM                   spark.serializer   \n",
       "10    drift              GMM                spark.locality.wait   \n",
       "11    drift              GMM              spark.executor.memory   \n",
       "12    drift           KMeans               spark.executor.cores   \n",
       "13    drift           KMeans  spark.shuffle.io.preferDirectBufs   \n",
       "14    drift           KMeans                   spark.serializer   \n",
       "15    drift           KMeans              spark.executor.memory   \n",
       "16    drift           Linear          spark.shuffle.file.buffer   \n",
       "17    drift           Linear      spark.reducer.maxSizeInFlight   \n",
       "18    drift           Linear         spark.io.compression.codec   \n",
       "19    drift           Linear               spark.executor.cores   \n",
       "20    drift         Logistic      spark.reducer.maxSizeInFlight   \n",
       "21    drift         Logistic                   spark.serializer   \n",
       "22    drift         Logistic             spark.shuffle.compress   \n",
       "23    drift         Logistic                 spark.rdd.compress   \n",
       "24    drift              MLP                   spark.serializer   \n",
       "25    drift              MLP               spark.executor.cores   \n",
       "26    drift              MLP      spark.reducer.maxSizeInFlight   \n",
       "27    drift              MLP                spark.locality.wait   \n",
       "28    drift              RFR          spark.shuffle.file.buffer   \n",
       "29    drift              RFR               spark.executor.cores   \n",
       "..      ...              ...                                ...   \n",
       "142   higgs              GBT                 spark.rdd.compress   \n",
       "143   higgs              GBT      spark.reducer.maxSizeInFlight   \n",
       "144   higgs              GMM               spark.executor.cores   \n",
       "145   higgs              GMM                spark.locality.wait   \n",
       "146   higgs              GMM             spark.shuffle.compress   \n",
       "147   higgs              GMM                 spark.rdd.compress   \n",
       "148   higgs           KMeans               spark.executor.cores   \n",
       "149   higgs           KMeans                 spark.rdd.compress   \n",
       "150   higgs           KMeans         spark.io.compression.codec   \n",
       "151   higgs           KMeans       spark.shuffle.spill.compress   \n",
       "152   higgs           Linear               spark.executor.cores   \n",
       "153   higgs           Linear                   spark.serializer   \n",
       "154   higgs           Linear                 spark.rdd.compress   \n",
       "155   higgs           Linear         spark.io.compression.codec   \n",
       "156   higgs         Logistic               spark.executor.cores   \n",
       "157   higgs         Logistic                 spark.rdd.compress   \n",
       "158   higgs         Logistic                spark.locality.wait   \n",
       "159   higgs         Logistic                   spark.serializer   \n",
       "160   higgs              MLP               spark.executor.cores   \n",
       "161   higgs              MLP       spark.storage.memoryFraction   \n",
       "162   higgs              MLP              spark.executor.memory   \n",
       "163   higgs              MLP                   spark.serializer   \n",
       "164   higgs              RFR                   spark.serializer   \n",
       "165   higgs              RFR                 spark.rdd.compress   \n",
       "166   higgs              RFR         spark.io.compression.codec   \n",
       "167   higgs              RFR       spark.storage.memoryFraction   \n",
       "168   higgs             Tree                   spark.serializer   \n",
       "169   higgs             Tree       spark.storage.memoryFraction   \n",
       "170   higgs             Tree               spark.executor.cores   \n",
       "171   higgs             Tree       spark.shuffle.spill.compress   \n",
       "\n",
       "             family      corr  \n",
       "0        clustering  0.761351  \n",
       "1        clustering  0.451746  \n",
       "2        clustering  0.376804  \n",
       "3        clustering  0.364779  \n",
       "4        regression  0.485571  \n",
       "5        regression  0.448519  \n",
       "6        regression  0.405312  \n",
       "7        regression  0.379202  \n",
       "8        clustering  0.547946  \n",
       "9        clustering  0.383796  \n",
       "10       clustering  0.339130  \n",
       "11       clustering  0.291832  \n",
       "12       clustering  0.727143  \n",
       "13       clustering  0.481616  \n",
       "14       clustering  0.378786  \n",
       "15       clustering  0.364115  \n",
       "16       regression  0.575189  \n",
       "17       regression  0.531954  \n",
       "18       regression  0.369945  \n",
       "19       regression  0.309268  \n",
       "20   classification  0.542878  \n",
       "21   classification  0.487533  \n",
       "22   classification  0.289387  \n",
       "23   classification  0.270352  \n",
       "24   classification  0.549565  \n",
       "25   classification  0.482878  \n",
       "26   classification  0.300109  \n",
       "27   classification  0.277702  \n",
       "28       regression  0.439532  \n",
       "29       regression  0.367706  \n",
       "..              ...       ...  \n",
       "142      regression  0.426161  \n",
       "143      regression  0.301010  \n",
       "144      clustering  0.872452  \n",
       "145      clustering  0.613022  \n",
       "146      clustering  0.513397  \n",
       "147      clustering  0.382530  \n",
       "148      clustering  0.796475  \n",
       "149      clustering  0.606863  \n",
       "150      clustering  0.524419  \n",
       "151      clustering  0.495950  \n",
       "152      regression  0.830322  \n",
       "153      regression  0.508103  \n",
       "154      regression  0.350343  \n",
       "155      regression  0.342071  \n",
       "156  classification  0.740345  \n",
       "157  classification  0.695201  \n",
       "158  classification  0.525535  \n",
       "159  classification  0.313255  \n",
       "160  classification  0.527106  \n",
       "161  classification  0.428811  \n",
       "162  classification  0.384922  \n",
       "163  classification  0.346812  \n",
       "164      regression  0.537009  \n",
       "165      regression  0.424055  \n",
       "166      regression  0.410668  \n",
       "167      regression  0.302768  \n",
       "168  classification  0.848753  \n",
       "169  classification  0.655175  \n",
       "170  classification  0.492446  \n",
       "171  classification  0.372471  \n",
       "\n",
       "[172 rows x 5 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv('usecase2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
